import requests
from bs4 import BeautifulSoup
import re

url = 'https://www.melon.com/chart/index.htm'
req_header = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'
}

html = requests.get(url, headers=req_header).text
soup = BeautifulSoup(html, 'html.parser')

#tb_list tr div.wrap_song_info a
# print(len(soup.select('#tb_list')))
# print(len(soup.select('#tb_list tr')))
# print(len(soup.select('#tb_list tr div.wrap_song_info')))
# print(len(soup.select('#tb_list tr div.wrap_song_info a')))
# print(len(soup.select("#tb_list tr div.wrap_song_info a[href*='playSong']")))

song_atag_list = soup.select("#tb_list tr div.wrap_song_info a[href*='playSong']")
song_list = []
for idx,song_atag in enumerate(song_atag_list,1):
    song_dict = {}
    song_title = song_atag.text
    link = song_atag['href']
    matched = re.search(r"(\d+)\)",link)
    song_id = matched.group(1)
    #print(matched.group(0), matched.group(1))
    song_url = 'https://www.melon.com/song/detail.htm?songId={}'.format(song_id)
    
    song_dict['title'] = song_title
    song_dict['url'] = song_url
    song_list.append(song_dict)
    
    #print(idx, song_title, song_url)
    #print(song_atag)



import requests
from bs4 import BeautifulSoup
import re

req_header = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.89 Safari/537.36'
}

song_lyric_lists = []

for song in song_list:
    html = requests.get(song['url'],headers=req_header).text
    soup = BeautifulSoup(html,'html.parser')
    
    song_lyric_dict = {}
    song_lyric_dict['곡명'] = song['title']
    song_lyric_dict['가수'] = soup.select('a[href*=".goArtistDetail"] span')[0].text
    song_lyric_dict['앨범'] = soup.select('div.meta dd')[0].text
    song_lyric_dict['발매일'] = soup.select('div.meta dd')[1].text
    song_lyric_dict['장르'] = soup.select('div.meta dd')[2].text
    #song_lyric_dict['좋아요'] = soup.select('span#d_like_count')[0].text
    lyric = soup.select('div#d_video_summary')[0].text
    regex = re.compile(r'[\n\r\t]')
    song_lyric_dict['가사'] = regex.sub('', lyric.strip())

    song_lyric_lists.append(song_lyric_dict)
    #print(song_lyric_dict)

# len(song_lyric_lists) #[output] 100


# song_lyric_lists 를 DataFrame으로 저장, 
# DB에 songs 테이블로 저장하세요
import pandas as pd
import numpy as np
import pymysql
pymysql.install_as_MySQLdb()
from sqlalchemy import create_engine

song_lyric_df = pd.DataFrame(columns=['곡명','가수','앨범','발매일','장르','가사'])

title = []
singer = []
album = []
publish = []
genre = []
lyric = []

for song in song_lyric_lists:
    title.append(song['곡명'])
    singer.append(song['가수'])
    album.append(song['앨범'])
    publish.append(song['발매일'])
    genre.append(song['장르'])
    lyric.append(song['가사'])
song_lyric_df['곡명'] = title
song_lyric_df['가수']= singer
song_lyric_df['앨범'] = album
song_lyric_df['발매일'] = publish
song_lyric_df['장르'] = genre
song_lyric_df['가사'] = lyric

song_lyric_df.index = np.arange(1, len(song_lyric_df)+1)
song_lyric_df

engine = create_engine("mysql+mysqldb://python:"+"python"+"@localhost/python_db", encoding="utf-8")
conn = engine.connect()
song_lyric_df.to_sql(name='songs', con=engine, if_exists='replace', index=False)
song_lyric_df


# import pandas as pd

# song_lyric_df = pd.DataFrame(columns=['곡명','가수','앨범','발매일','장르','가사'])
# for song in song_lyric_lists:
#     series_obj = pd.Series(song)
#     song_lyric_df = song_lyric_df.append(series_obj, ignore_index=True)

